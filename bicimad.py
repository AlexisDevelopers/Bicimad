# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qjJxcjJrO8Yo41gpHkfBQp7jyNUylHgB
"""

# CELL 1: Import libraries
import pandas as pd
import math
import os
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import auth
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error


# CELL 2: Upload JSON files manually via sidebar
# (No code needed here — click the folder icon at left > upload 3 JSON files)

# CELL 3: Authenticate with Google Drive
auth.authenticate_user()
drive_service = build('drive', 'v3')

# CELL 4: Load JSONs, compute distances
json_files = ["202111_movements.json", "202210_movements.json", "202212_movements.json"]
distancias = []  # List to store calculated distances

# Haversine formula to calculate distance between two lat/lon points (in meters)
def haversine_distance(lat1, lon1, lat2, lon2):
    """Calculates the distance between two geographical points using the Haversine formula."""
    R = 6371000  # Radius of Earth in meters
    dlat = math.radians(lat2 - lat1)
    dlon = math.radians(lon2 - lon1)
    a = math.sin(dlat / 2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon / 2)**2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    return R * c  # Resulting distance in meters

# Loop through each file to extract latitudes and longitudes from the 'stations' column and calculate distances
for file in json_files:
    if not os.path.exists(file):
        print(f"⚠️ Warning: {file} not found. Skipping.")
        continue
    df = pd.read_json(file, encoding="ISO8859-1", lines=True)
    print(f"✅ Loaded {file} with {len(df)} rows")
    df.dropna(inplace=True)  # Remove rows with missing values

    # Extract latitudes and longitudes from the 'stations' column (which is a list of dictionaries)
    origin_latitudes = []
    origin_longitudes = []

    # Iterate through each row's 'stations' list
    for row in df['stations']:
        for station in row:  # Each row contains a list of stations
            if 'latitude' in station and 'longitude' in station:
                # Append latitudes and longitudes of the stations
                origin_latitudes.append(float(station['latitude']))  # Convert to float
                origin_longitudes.append(float(station['longitude']))  # Convert to float

    # Check if there are enough stations (at least 2) for distance calculation
    if len(origin_latitudes) >= 2 and len(origin_longitudes) >= 2:
        # Calculate distances between consecutive stations
        for i in range(len(origin_latitudes)-1):  # Subtract 1 to avoid out of range error
            try:
                dist = haversine_distance(origin_latitudes[i], origin_longitudes[i], origin_latitudes[i+1], origin_longitudes[i+1])
                distancias.append(dist)  # Append the calculated distance
            except:
                continue  # Skip if any error occurs during distance calculation

print(f"📊 Total distances extracted: {len(distancias)}")

# CELL 5: Print out the stations data to inspect its structure
for file in json_files:
    df = pd.read_json(file, encoding="ISO8859-1", lines=True)
    print(f"✅ Loaded {file} with {len(df)} rows")

    # Print the first row of the 'stations' column to inspect the structure
    print(df['stations'].head())
    break  # Only print for the first file for now

# CELL 6: Load JSONs, compute distances
# Save the calculated distances into a DataFrame
df_viajes = pd.DataFrame({"distancias": distancias})
df_viajes['distancia_media'] = df_viajes['distancias'].mean()  # Calculate the mean distance
df_viajes.to_csv("viajes_final.csv", index=False)  # Save the results to CSV

# Upload the final CSV to Google Drive
media = MediaFileUpload('viajes_final.csv', mimetype='text/plain', resumable=True)
upload_final = drive_service.files().create(
    body={'name': 'viajes_final.csv', 'mimeType': 'text/plain'},
    media_body=media,
    fields='id'
).execute()
print(f'File ID Final: {upload_final.get("id")}')

# CELL 7: Train regression models

# Prepare the data for training: features (X) and target (y)
X = df_viajes.drop(['distancias'], axis=1)  # Features (no distances)
y = df_viajes['distancias']  # Target (distances)

# Reduce the test size to speed up training
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)  # 10% test size

# Standardize the data (scaling features for better model performance)
scaler = StandardScaler().fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define the models for training (removing MLP and KNN for simplicity)
modelos = {
    'Linear Regression': LinearRegression(),
    'Ridge': Ridge(),
    'SGD': SGDRegressor(),
}

# Train each model and print the R² score, MSE, and MAE
for nombre, modelo in modelos.items():
    modelo.fit(X_train_scaled, y_train)
    y_pred = modelo.predict(X_test_scaled)
    score = modelo.score(X_test_scaled, y_test)
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    print(f"{nombre}: R²={score:.4f} | MSE={mse:.2f} | MAE={mae:.2f}")

# CELL 7: Visualization of the distribution of distances

plt.figure(figsize=(8,5))
sns.histplot(distancias, kde=True, bins=40, color='skyblue')
plt.title('Distribución de Distancias Bicimad')
plt.xlabel('Distancia (m)')
plt.ylabel('Frecuencia de los Viajes')
plt.grid(True)
plt.show()

# CELL 8: Análisis de patrones útiles para recomendaciones operativas

# 1. Estadísticas descriptivas de distancias
print("📈 Estadísticas de las distancias:")
print(df_viajes['distancias'].describe())

# 2. Segmentación de distancias en rangos operativos
df_viajes['rango'] = pd.cut(df_viajes['distancias'],
                             bins=[0, 500, 1000, 2000, 5000, 10000],
                             labels=['0-500m', '501-1000m', '1001-2000m', '2001-5000m', '5001-10000m'])

# 3. Conteo por rango
rango_counts = df_viajes['rango'].value_counts().sort_index()
print("\n📊 Distribución por rangos de distancia:")
print(rango_counts)

# 4. Visualización de la segmentación
plt.figure(figsize=(7,5))
rango_counts.plot(kind='bar', color='lightgreen', edgecolor='black')
plt.title('Frecuencia de Viajes por Rango de Distancia')
plt.xlabel('Rango de Distancia')
plt.ylabel('Cantidad de Viajes')
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()